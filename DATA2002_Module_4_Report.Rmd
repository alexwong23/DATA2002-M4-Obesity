---
title: "DATA2002 Module 4 Report"
author: "Group 9 (460352996,480407614,480145820,470066919)"
output: 
  html_document:
    theme: simplex
    code_folding: hide
    toc: true
    toc_float: true
---

```{r load_packages, include=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(janitor)
library("readxl")
library(ggfortify)
library(GGally)
library(qtlcharts)
library(leaps)
library(sjPlot)
library(pheatmap)
```

***

## 1. Introduction

The data set is adapted from th  

### 1.1 Sampling method and potential biases



### 1.2 Data import, processing and cleaning



```{r import_data, message=FALSE, warning=FALSE}
data = read_tsv("bodyfat.txt", na = c("NA"))
data = data %>% janitor::clean_names()
glimpse(data)
```

***
## 2. Analysis
### 2.1 Body Fat
provide context to the qn!!! why use linear regression on full model...

##### 2.1.1 Defining the model with population parameters
$$
Percentage of Body Fat = \beta_0 + \beta_1density + \beta_2age + \beta_3weight + \beta_4height\\
+ \beta_5neck + \beta_6chest + \beta_7abdomen + \beta_8waist + \beta_9hip + \beta_{10}thigh\\ + \beta_{11}knee + \beta_{12}ankle + \beta_{13}bicep + \beta_{14}forearm + \beta_{15}wrist + \epsilon
$$

##### 2.1.2 Linear regression assumptions for the full model
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.
```{r }
pbf_lm = lm(pct_bf ~ ., data)
summary(pbf_lm)
autoplot(pbf_lm, which = 1:2) + theme_bw()
```
<ol>
<li>Linearity: In the scatterplot above, .</li>
<li>Homoskedasticity: In the scatterplot above, .</li>
<li>Normality: In the QQ plot above, .</li>
</ol>

##### 2.1.3 Dropping variables using the AIC starting from the full model
```{r }
pbf_step = step(pbf_lm, direction = "backward")
```

Backwards selection using the AIC dropped all variables except for age, density and abdomen which are kept in the model.

##### 2.1.4 Fitted model for the model selected by the step-wise procedure.
$$
Percentage of Body Fat = 442.3755 - 406.493 \times density\\
+ 0.0118 \times age + 0.0576 \times abdomen\\
$$
Looking at the $R^2$ value (multiple R-squared) from the summary output, 98% of the variability of age is explained by the regression on density, age and abdomen circumference.

<ol>
<li>On average, holding the other variables constant, a 1 $gm/cm^3$ increase in density leads to a 400 unit decrease in percentage of body fat.</li>
<li>On average, holding the other variables constant, a one year increase in age leads to a 0.0118 unit increase in percentage of body fat.</li>
<li>On average, holding the other variables constant, a one year increase in abdomen circumference leads to a 0.0576 unit increase in percentage of body fat.</li>
</ol>
```{r }
#options("scipen"=100, "digits"=4)
summary(pbf_step)
#options("scipen"=-100, "digits"=4)
```

##### 2.1.5 Linear regression assumptions for the stepwise model - why do this? same as previous??
```{r }
autoplot(pbf_step, which = 1:2) + theme_bw()
```

## 2. Analysis
### 2.1 Prediction for Obesity
Due to the increasing consumptions of fast food and the increasing convenience of food deliveries, concerns about obesity level is rising throughput the world and has reached a new high. This increasing concern has lead to an increasing need to measure obesity accurately and percentage body fat is arguably the most accurate measure by far. However, the calculation of body fat is difficult and many has switched to Body Mass Index (BMI) for simpler calculation. This section is looking at comparing the results from predicting body fat percentage using other body measurements and  predicting BMI using other body measurements to determine wh body measurement is the most important in determining obesity.

#### Data import, Processing and Cleaning
```{r}
data = read.delim("bodyfat.txt") %>% janitor::clean_names()
glimpse(data)
#Introduce BMI Varaible
data=data %>% mutate(bmi=(data$weight/(data$height^2))*703,)
#Isolate the dataset only contain Body Measurements
data_bf = data[-c(1,3:5,17)]
#Isolate the dataset to only contain Body Measurements and as weight and height were included in the BMI formula, it is also removed
data_bmi = data[-c(1:5)]
```

#### Body Fat Percentage
##### Data Visualisation
```{r}
qtlcharts::iplotCorr(data_bf)
```
Based on the interactive correlation matrix, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is adopted.

##### Multiple Regression
```{r}
bf_lm = lm(pct_bf~.,data=data_bf)
summary(bf_lm)
```
Using the individual p-value method, the varaibles that need to be dropped are chest, waist, thigh, knee,ankle, bicep, forearm with ankle being the first to drop down due to its high p-value. However, to double check, the AIC criterion will also be considered.

```{r}
bf_step_back = step(bf_lm, direction = "backward",trace = FALSE)
summary(bf_step_back)
```
Based on the backward selection model, the fitted model has become:

$\hat{body_fat} = 1.52 -0.3965neck - 0.128chest + 1.01805abdomen -0.28758hip + 0.26bicep -1.55084wrist $

Finally, to check assumption, we perform the ggfortify function.

```{r}
par(mfrow=c(1,2))
plot(bf_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a slight variation; but given that body fat is hard to predict, this is acceptable.

##### Final fitted model
$\hat{body_fat} = 1.52 -0.3965neck - 0.128chest + 1.01805abdomen -0.28758hip + 0.26bicep -1.55084wrist $

#### BMI
For this analysis, the formula of BMI is $BMI = \frac{Weight (lbs)*703}{Height(in)^2}$

##### Data Visualisation
```{r}
qtlcharts::iplotCorr(data_bmi)
```
Based on the interactive correlation matrix, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is adopted.

##### Multiple Regression

```{r}
bmi_lm = lm(bmi~.,data=data_bmi)
summary(bmi_lm)
```

Using the individual p-value method, the varaibles that need to be dropped are hip, ankle, bicep, forearm and wrist. To double check, the AIC criterion will also be considered.

```{r}
bmi_step_back = step(bmi_lm, direction = "backward",trace = FALSE)
summary(bmi_step_back)
```

Based on the backward selection model, the fitted model has become:

$\hat{bmi} = -10.94 +0.161chest + 0.127abdomen + 0.050hip + 0.150 thigh - 0.23knee + 0.115forearm $

Finally, to check assumption, we perform the ggfortify function.

```{r}
par(mfrow=c(1,2))
plot(bmi_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a fan shaped plot which indicates that the assumption of homogeneous variance is violated. We can use a log transformed response and re-fit the linear regression.

```{r}
ln_bmi_lm = lm(log(bmi)~.,data=data_bmi)
summary(ln_bmi_lm)
ln_bmi_step_back = step(ln_bmi_lm, direction = "backward",trace = FALSE)
summary(ln_bmi_step_back)
par(mfrow=c(1,2))
plot(ln_bmi_step_back,which=1:2) + theme_bw()
```

```{r}
sjPlot::tab_model(bmi_step_back, ln_bmi_step_back, digits = 5, show.ci = FALSE)
```


##### Final Fitted Model

$log(\hat{bmi}) = 1.83 +0.0058chest + 0.0052abdomen + 0.0064 thigh -0.0065knee +        0.0028bicep + 0.0040 forearm $.

#### Conclusion
```{r}
sjPlot::tab_model(bf_step_back, ln_bmi_step_back, digits = 5, show.ci = FALSE)
```

Through looking at the two models, we can see that using simply body measurements, it is easier to predict changes in bmi rather than percentage body fat. From the models, measurements of abdomen appears to have the greatest influence on both body fat and bmi and hence any increase should be treated with caution.



### 2.2 Weight
##### 2.2.1 Defining the model with population parameters
Since the body density is calculated based on weight, height, neck and other variables below in our data set. It is better not include it in our full model.
$$
Body Weight = \beta_0  + \beta_1age + \beta_2percentageofbodyfat + \beta_3height\\
+ \beta_4neck + \beta_5chest + \beta_6abdomen + \beta_7waist + \beta_8hip + \beta_{9}thigh\\ + \beta_{10}knee + \beta_{11}ankle + \beta_{12}bicep + \beta_{13}forearm + \beta_{14}wrist + \epsilon
$$
##### 2.2.2 Check Assumptions:
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.

```{r }
dataqf1=within(data,rm(density))
weight_lm = lm(weight ~ ., dataqf1)
summary(weight_lm)
autoplot(weight_lm, which = 1:2) + theme_bw()
```
In the plot above the residuals are above zero from the beginning, then they go below zero and end up again above zero for the end.
This means the linearity assumption fails. We underestimate the weight variable at the start and the end and overestimate the weight at medium.
To address this problem, I transform the weight to sqrt(weight).
```{r}
dataqf=dataqf1%>%mutate(weight=weight^(1/2))
weight_lmqf = lm(weight ~ ., dataqf)
summary(weight_lmqf)
autoplot(weight_lmqf, which = 1:2) + theme_bw()
```
The linearity looks much better now.
<li>Homoskedasticity: In the scatterplot above,The spread looks reasonably constant.  .</li>
<li>Normality: In the QQ plot above, the tail is below the diagonal line and the first value is a significant outlier. However, we have quite a large sample size so we can rely on the central limit theorem to give us approximately valid inferences.</li>
```{r}
qtlcharts::iplotCorr(dataqf)
```
It seems there is no direct linear relationship between age and weight. I will do further reserch to work out the appropriate model.
##### 2.2.3 Dropping and adding variables using the AIC starting from the full model
```{r}
M0 = lm(weight ~ 1, data = dataqf)
step.fwd.aic = step(M0, scope = list(lower = M0, upper = weight_lmqf), direction = "forward", trace = FALSE)
step.back.aic = step(weight_lmqf, direction = "backward", trace = FALSE)
summary(step.back.aic)
summary(step.fwd.aic)
```
Both forward and backward search using AIC give the same result. 
##### 2.2.4 Fitted model for the model selected by the step-wise procedure.
$$
sqrt(Weight) = -5.547979   + 0.030800    \times hip+ 0.032385 \times neck + 0.076563    \times height\\
+ 0.031738 \times chest + 0.017835    \times thigh +0.019509    \times abdomen   + 0.023096    \times ankle\\
+ 0.018840    \times bicep +0.017246    \times forearm + 0.050826    \times wrist - 0.003182  \times age + 0.018287 
\times knee
$$
Looking at the $R^2$ value (multiple R-squared) from the summary output, 98% of the variability of age is explained by the regression on hip, neck, height, chest, thigh, abdomen, ankle, bicep, firearm, wrist, age and knee circumference.
<ol>
<li>On average, holding the other variables constant, a 1 unit increase in hip leads to a 0.031 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in neck leads to a 0.032 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in height leads to a 0.077 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in chest leads to a 0.032 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in thigh leads to a 0.018 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in abdomen leads to a 0.02 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in ankle leads to a 0.023 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in bicep leads to a 0.0188 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in forearm leads to a 0.017 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in wrist leads to a 0.05 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in age leads to a -0.003 unit increase in sqrt(weight).</li>
<li>On average, holding the other variables constant, a 1 unit increase in knee leads to a 0.018 unit increase in sqrt(weight).</li>
### 2.3 Body Density

##### 2.3.1 Defining the model with population parameters
$$
Density = \beta_0 + \beta_1density + \beta_2age + \beta_3weight + \beta_4height\\
+ \beta_5neck + \beta_6chest + \beta_7abdomen + \beta_8waist + \beta_9hip + \beta_{10}thigh\\ + \beta_{11}knee + \beta_{12}ankle + \beta_{13}bicep + \beta_{14}forearm + \beta_{15}wrist + \epsilon
$$
```{r}
cor_matrix <- cor(data)
pheatmap(cor_matrix, display_numbers = T,na.rm=T)
```

Above matrix has shown the interactice correlation between variables. Notbaly, Pct.BF has a -0.99 relationship with Density, which means Pct.BF could be used to expalin Density. Meanwhile, variables having similar properties are linked together, which could be useful for generating groups.

##### 2.3.2 Check Assumptions:
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.
```{r}
data1<-data[,-2]
```

```{r}
M0 <- lm(density ~ 1, data = data1)  # Null model
M1 <- lm(density ~ ., data = data1)  # Full model
autoplot(M1,which=1:2)+theme_bw()
round(summary(M1)$coef, 3)
```
```{r}
step.fwd.aic <- step(M0, scope = list(lower = M0, upper = M1), direction = "forward", trace = FALSE)
summary(step.fwd.aic)
step.back.aic <- step(M1, scope = list(lower = M0, upper = M1), direction = "backward", trace = FALSE)
summary(step.back.aic)
```
```{r}
exh <- regsubsets(density~., data = data1, nvmax = 15)
plot(exh,scale="bic")
```
It is best to choose age, weight, height, neck and chest for conducting the relationship analysis with body density.

##### 2.3.3 Dropping variables using the AIC starting from the full model
**Hypothesis**:
$$
H_0: \alpha_1 = \alpha_1 = ... = \alpha_g \\
H_1:  \text{ Not all means are the same.}\\
$$
**Assumptions:**
<ol>
<li>$\epsilon_{ijk} \sim N(0, \sigma^2)$</li>
</ol>

```{r}
M2<- lm(formula = density ~ age + weight + height + neck + chest + abdomen , 
    data = data1)
summary(M2)
M3<- lm(formula = density ~ height + neck + chest + abdomen , 
    data = data1)
summary(M3)


relweights <- function(fit,...){
  R <- cor(fit$model)
  nvar <- ncol(R)
  rxx <- R[2:nvar, 2:nvar]
  rxy <- R[2:nvar, 1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta %*% t(evec)
  lambdasq <- lambda ^ 2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta ^ 2)
  rawwgt <- lambdasq %*% beta ^ 2
  import <- (rawwgt / rsquare) * 100
  import <- as.data.frame(import)
  row.names(import) <- names(fit$model[2:nvar])
  names(import) <- "Weights"
  import <- import[order(import),1, drop=FALSE]
  dotchart(import$Weights, labels=row.names(import),
           xlab="% of R-Square", pch=19,
           main="Relative Importance of Predictor Variables",
           sub=paste("Total R-Square=", round(rsquare, digits=3)),
           ...)
  return(import)
}
relweights(M3, col="blue")
```

##### 2.3.4 Fitted model for the model selected by the step-wise procedure.
$$
Body Density = 1.0746853 + 0.0011729 \times Height\\
+ 0.0012053 \times Neck + 0.004285 \times Chest\\ - 0.0020607 \times Abdomen\\
$$

Looking at the $R^2$ value (multiple R-squared) from the summary output, 71.39% of the variability of density is explained by the regression on percentage of Height, Neck, Chest, Abdomen.
<ol>
<li>On average, holding the other variables constant, a 1% increase in Height leads to a 0.0012% unit increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Neck leads to a 0.0012% increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Chest leads to a 0.0043% increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Abdomen leads to a 0.0021% decrease in Density</li>
</ol>

##### 2.3.5 Linear regression assumptions for the stepwise model - why do this? same as previous??
```{r}
autoplot(M3,which=1:2)+theme_bw()
```

**Hypothesis**:
$$
H_0: \alpha_1 = \alpha_1 = ... = \alpha_g \\
H_1:  \text{ Not all means are the same.}\\
$$
**Assumptions:**
<ol>
<li>$\epsilon_{ijk} \sim N(0, \sigma^2)$</li>
</ol>


### 2.4 Age
#### Predicting percentage of body fat from age
Fit a simple linear regression to the data to assess whether the age has an influence on the percentage of body fat.
Taking the log of % of body fat improves the fit by altering the scale and making the variable more "normally" distributed.
$$
X = \beta_0 + \beta_1log(Y) + \epsilon
$$

```{r }
p = data %>% ggplot() + aes(x = age, y = pct_bf) + geom_point() + 
    geom_smooth(method = "lm", se = FALSE) + theme_bw() +
    scale_y_continuous(labels = scales::number) + 
    scale_x_continuous(labels = scales::number) +
    labs(x = "Age", y = "Body Fat Percentage", title = "Proportion of Body Fat Percentage based on Age", fill = "Percentage of Body Fat", caption = "Source: SOCR Data BMI Regression") +
    scale_y_log10()
p
```


```{r }
data.lm = lm(log1p(pct_bf) ~ age, data)
summary(data.lm)
```

A one year increase in age would lead to a 1.15% increase in percentage of body fat.

```{r }
predict(data.lm, data = data.frame(x = 50), interval = "prediction", level = 0.95)

p + geom_segment(aes(y = 0, yend = 2.633523, x = 50, xend = 50), 
    colour = "gray") + geom_segment(aes(y = 2.633523, yend = 2.633523,
    x = 25, xend = 50), colour = "gray") + scale_x_continuous(limits = c(25, 75), expand = c(0, 0), labels = scales::number) + scale_y_continuous(limits = c(0, 50), expand = c(0, 0), labels = scales::number)
```

```{r }
par(mfrow = c(1, 2))
plot(data.lm, which = 1:2)
autoplot(data.lm, which = 1:2) + theme_bw()
tlm = lm(pct_bf ~ log(age), data)
summary(tlm)
autoplot(tlm, which = 1:2) + theme_bw()
```
```{r }
#install.packages("tidyr")
#install.packages("sjPlot")
ttlm = lm(log1p(pct_bf) ~ log(age), data)
sjPlot::tab_model(data.lm, tlm, ttlm, digits = 5, show.ci = FALSE)
```


##### 2.4 LINEAR REGRESSION WITH AGE

provide context to the qn!!! why use linear regression on full model...

##### 2.4.1 Defining the model with population parameters
$$
Age = \beta_0 + \beta_1density + \beta_1pctBodyFat + \beta_2weight + \beta_3height + \beta_4neck + \beta_5chest + \\
\beta_6abdomen + \beta_7waist + \beta_8hip + \beta_9thigh + \beta_{10}knee + \beta_{11}ankle + \beta_{12}bicep + \\
\beta_{13}forearm + \beta_{14}wrist + \epsilon
$$

##### 2.4.2 Linear regression assumptions for the full model - what is x and y?
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.
```{r }
age_lm = lm(age ~ ., data)
summary(age_lm)
autoplot(age_lm, which = 1:2) + theme_bw()
```
<ol>
<li>Linearity: In the scatterplot above, there is no obvious pattern between the residual and fitted values. Hence, we have not misspecified the model.</li>
<li>Homoskedasticity: In the scatterplot above, the residuals do not appear to be fanning out or changing their variability over the range of the fitted values so the constant error variance assumption is met.</li>
<li>Normality: In the QQ plot above, the points are reasonably close to the diagonal line. Approximately 6 of the points at the bottom do not lie on the line, but the departure is not severe enough to cause any concern. Therefore, we are confident that the normal assumption is at least approximately satisfied.</li>
</ol>

##### 2.4.3 Dropping variables using the AIC starting from the full model
```{r }
age_step = step(age_lm, direction = "backward")
```

Backwards selection using the AIC dropped variables waist, height, density, bicep and hip but decided to keep chest in the model.

##### 2.4.4 Fitted model for the model selected by the step-wise procedure.
$$
Age = -74.36348 + 0.3153 \times pctBodyFat -0.4782 \times weight + 0.8185 \times neck\\
+ 0.32544 \times chest + 0.8824 \times abdomen -1.6054 \times thigh + 1.8424 \times knee\\
- 0.7486 \times ankle -0.6929 \times forearm + 6.2789 \times wrist
$$
Looking at the $R^2$ value (multiple R-squared) from the summary output, 50% of the variability of age is explained by the regression on percentage of body fat, weight, neck, chest, abdomen, thigh, knee, ankle, forearm and wrist.

<ol>
<li>On average, holding the other variables constant, a 1% increase in body fat leads to a 0.31 unit increase in age.</li>
<li>On average, holding the other variables constant, a 1 year increase in age leads to a 0.31% increase in bodyFat.</li>
<li></li>
<li></li>
<li></li>
</ol>
```{r }
summary(age_step)
```

##### 2.4.5 Linear regression assumptions for the stepwise model - why do this? same as previous??
```{r }
autoplot(age_step, which = 1:2) + theme_bw()
```

## 3. Limitations

## 4. Conclusion

## 5. References
<ol>
<li>  </li>
</ol> 

