---
title: "DATA2002 Module 4 Report"
author: "Group 9 (460352996,480407614,480145820,470066919)"
output: 
  html_document:
    theme: simplex
    code_folding: hide
    toc: true
    toc_float: true
---

```{r load_packages, include=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(janitor)
library("readxl")
library(ggfortify)
library(GGally)
library(qtlcharts)
library(leaps)
library(sjPlot)
library(pheatmap)
library(partykit)
library(rpart)
library(caret)
```

***

## 1. Introduction

Excess weight, especially obesity, has become an epidemic in the 21st century and resulted in many significant health and economic consequences for the global population (Stein and Colditz, 2004). In Australia, this epidemic has also spread as 2 in 3 adults are classified as overweight or obese (Australian Institute of Health and Welfare). Researches has shown that this epidemic is more common in males than females and hence, BYU Human Performance Research Center has collected data from 250 men of various age and obtained estimates of the percentage of body fat through underwater weighing and various body circumference measurements (Rahman and Harding, 2013; DASL, n.d.). As body fat percentage is difficult to calculate in real life, the value for body fat percentage was derived from body density using the Siri’s 1956 equation.


### 1.1 Sampling method and potential biases
Few details were provided with regards to the sampling method. However, from looking at the dataset, there is a gender bias as the epidemic question is one related to both genders, yet only male were involved in the sample. This suggests that any analysis based on this dataset cannot be applied to the whole population but only the male population.


### 1.2 Data import, processing and cleaning
```{r import_data, message=FALSE, warning=FALSE}
data = read.delim("bodyfat.txt") %>% janitor::clean_names()
data = data %>%
  mutate(bmi = (data$weight/(data$height ^ 2)) * 703,
         overweight = case_when(
          bmi >= 25 ~ 1,
          bmi < 25 ~ 0))
data$overweight = as.numeric(data$overweight)
#colnames(data)
data_bmi = data[-c(1:2,4:5,18)]
data_bf = data[-c(1,3:5,17:18)]
data_density = data[-c(2:5,17:18)]
data_overweight = data[-c(4:5,17)]
glimpse(data)
```

### 1.3 Data Visualisation

#### 1.3.1 Obesity and Age
```{r message=FALSE, warning=FALSE}
ggplot(data, aes(x=age,fill=overweight)) + geom_bar() +scale_fill_brewer(palette = "Paired") +labs(x='Age',y='Count', title = 'Severity of Obesity Across Different Age Groups',caption='Source: SOCR Data') +theme(plot.title = element_text(hjust = 0.5, face = 'bold'))+theme(axis.text.x = element_text(angle = 50, hjust = 1))+scale_fill_discrete(name = "Overweight", labels = c("Not Overweight", "Overweight"))
```

From looking at the graph, it can be observed that most of the sample comes from the age group between 40-60 and the number of people who appear to be overweight seems to be distributed evenly across the population.

#### 1.3.2 Body Measurements

```{r}
boxplot(data$neck,data$chest,data$abdomen,data$waist,data$bicep,data$forearm,data$wrist,main = "Upper Body Measurements from SOCR Data",names = c("Neck","Chest","Abdomen","Waist","Bicep","Forearm","Wrist"))
boxplot(data$hip,data$knee,data$thigh,data$ankle,main = "Lower Body Measurements from SOCR Data",names = c("Hip","Knee","Thigh","Ankle"))
```

From the two boxplots, the body measurement dataset appears relatively symmetrical and contains a few outliers. This may propose some problems in the later stages of the analysis.

### 1.4 Analysis Approach
This report aims to determine an alternative method to determine "overweight" individuals oppose to body fat percentage and the two alternative methods considered are:

1. BMI
2. Body Density

The analysis will first begin through determining how much variation in body fat percentage can be explained by simply body measurements and the number of measurements that is significant in building an accurate prediction model to examine the ease of calculation.

Then similar analysis will be conducted on BMI and Body Density where the end result will be compared together to determine which method can be explained the best using simple body measurements and offers easier and simpler interpretation.

Lastly, a binary indicator will be added to differentiate the sample into overweight individuals (1) and non-overweight individuals (0) using BMI as the guiding criteria. A logistic regression is run on the binary indicator with BMI, body density and age for a simpler model to determine the odds of an individual being obesed.

***
## 2. Analysis
Due to the increasing consumptions of fast food and the increasing convenience of food deliveries, concerns about obesity level is rising throughput the world and has reached a new high. This increasing concern has lead to an increasing need to measure obesity accurately and percentage body fat is arguably the most accurate measure by far. However, the calculation of body fat is difficult and many has switched to Body Mass Index (BMI) for simpler calculation. This section is looking at how much variation that simple body measurements can explain in the three methods of interest - body fat percentage, BMI and body density.

### 2.1 Body Fat Percentage
##### 2.1.1 Data Visualisation

=======

```{r}
qtlcharts::iplotCorr(data_bf)
```

Based on the interactive correlation matrix above, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is adopted.

#### 2.1.2 Multiple Regression and Variable Selection
```{r}
bf_lm = lm(pct_bf~.,data=data_bf)
summary(bf_lm)
```
Using the individual p-value method, the varaibles that need to be dropped are chest, waist, thigh, knee,ankle, bicep, forearm with ankle being the first to drop down due to its high p-value. However, to double check, the AIC criterion will also be considered.

```{r}
bf_step_back = step(bf_lm, direction = "backward",trace = FALSE)
summary(bf_step_back)
```
Based on the backward selection model, the fitted model has become:

$$ \hat{Body - Fat} = 1.52 -0.3965Neck - 0.128Chest + 1.01805Abdomen -0.28758Hip + 0.26Vicep -1.55084Wrist $$

#### 2.1.3 Check Assumptions
Finally, to check assumption, we perform the ggfortify function.
```{r}
par(mfrow=c(1,2))
plot(bf_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a slight variation; but given that body fat is hard to predict, this is acceptable.

#### 2.1.4 Final fitted model
```{r}
relbf <- function(fit,...){
  R <- cor(fit$model)
  nvar <- ncol(R)
  rxx <- R[2:nvar, 2:nvar]
  rxy <- R[2:nvar, 1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta %*% t(evec)
  lambdasq <- lambda ^ 2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta ^ 2)
  rawwgt <- lambdasq %*% beta ^ 2
  import <- (rawwgt / rsquare) * 100
  import <- as.data.frame(import)
  row.names(import) <- names(fit$model[2:nvar])
  names(import) <- "Weights"
  import <- import[order(import),1, drop=FALSE]
  dotchart(import$Weights, labels=row.names(import),
           xlab="% of R-Square", pch=19,
           main="Relative Importance of Predictor Variables",
           sub=paste("Total R-Square=", round(rsquare, digits=3)),
           ...)
  return(import)
}
relbf(bf_step_back, col="blue")
```

The final model is:

$$ \hat{body-fat} = 1.52 -0.3965neck - 0.128chest + 1.01805abdomen -0.28758hip + 0.26bicep -1.55084wrist $$

and abdomen is relatively the most important predictor for predicting body fat percentage.

Looking at the $R^2$ value (multiple R-squared) from the summary output, 73.5% of the variability of density is explained by the regression on percentage of Height, Neck, Chest, Abdomen.

<ol>
<li>On average, holding the other variables constant, a 1 unit increase in Neck leads to a 0.3965 unit decrease in Body Fat Percentage </li>
<li>On average, holding the other variables constant, a 1 unit increase in Chest leads to a 0.128 unit decrease in Body Fat Percentage </li>
<li>On average, holding the other variables constant, a 1 unit increase in Abdomen leads to a 1.01805 unit increase in Body Fat Percentage </li>
<li>On average, holding the other variables constant, a 1 unit increase in Hip leads to a 0.28758 unit decrease in Body Fat Percentage </li>
<li>On average, holding the other variables constant, a 1 unit increase in Bicep leads to a 0.26 unit increase in Body Fat Percentage </li>
<li>On average, holding the other variables constant, a 1 unit increase in Wrist leads to a 1.5508 unit decrease in Body Fat Percentage </li>
</ol>

***
### 2.2 BMI
For this analysis, the formula of BMI is 

$$ BMI = \frac{Weight (lbs)*703}{Height(in)^2} $$

#### 2.2.1 Defining the model with population parameters

$$
BMI = \beta_0 + \beta_1Neck + \beta_2Chest \\ + \beta_3Abdomen + \beta_4Waist + \beta_5Hip + \beta_6Thigh + \beta_7Knee + \beta_8Ankle \\+ \beta_9Bicep + \beta_{10}Forearm + \beta_{11}Wrist + \epsilon
$$

```{r}
qtlcharts::iplotCorr(data_bmi)
```

Based on the interactive correlation matrix, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is also adopted here.

#### 2.2.2 Multiple Regression with Variable Selection

```{r}
bmi_lm = lm(bmi~.,data=data_bmi)
summary(bmi_lm)
```

Using the individual p-value method, the varaibles that need to be dropped are hip, ankle, bicep, forearm and wrist. To double check, the AIC criterion will also be considered.

```{r}
bmi_step_back = step(bmi_lm, direction = "backward",trace = FALSE)
summary(bmi_step_back)
```

Based on the backward selection model, the fitted model has become:

$$ \hat{BMI} = -10.94 +0.161Chest + 0.127Abdomen + 0.050Hip + 0.150 Thigh - 0.23Knee + 0.115Forearm $$

#### 2.2.3 Check Assumptions
Finally, to check assumption, we perform the ggfortify function.

```{r}
par(mfrow=c(1,2))
plot(bmi_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a fan shaped plot which indicates that the assumption of homogeneous variance is violated. We can use a log transformed response and re-fit the linear regression.

The new model will become:
$log(\hat{bmi}) = 1.83 +0.0058chest + 0.0052abdomen + 0.0064 thigh -0.0065knee +        0.0028bicep + 0.0040 forearm $.

```{r}
ln_bmi_lm = lm(log(bmi)~.,data=data_bmi)
summary(ln_bmi_lm)
ln_bmi_step_back = step(ln_bmi_lm, direction = "backward",trace = FALSE)
summary(ln_bmi_step_back)
par(mfrow=c(1,2))
plot(ln_bmi_step_back,which=1:2) + theme_bw()
```

```{r}
sjPlot::tab_model(bmi_step_back, ln_bmi_step_back, digits = 5, show.ci = FALSE)
```

However, although the transformation has aided with the homogeneous variance assumption, the interpretation itself does not make much sense - BMI is determined by an increase in value, not the increase in percentage change. Hence in the final comparison, we will use the untransformed model.

#### 2.2.4 Final Fitted Model
```{r}
relbmi <- function(fit,...){
  R <- cor(fit$model)
  nvar <- ncol(R)
  rxx <- R[2:nvar, 2:nvar]
  rxy <- R[2:nvar, 1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta %*% t(evec)
  lambdasq <- lambda ^ 2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta ^ 2)
  rawwgt <- lambdasq %*% beta ^ 2
  import <- (rawwgt / rsquare) * 100
  import <- as.data.frame(import)
  row.names(import) <- names(fit$model[2:nvar])
  names(import) <- "Weights"
  import <- import[order(import),1, drop=FALSE]
  dotchart(import$Weights, labels=row.names(import),
           xlab="% of R-Square", pch=19,
           main="Relative Importance of Predictor Variables",
           sub=paste("Total R-Square=", round(rsquare, digits=3)),
           ...)
  return(import)
}
relbmi(bmi_step_back, col="blue")
```

The final model is:

$$\hat{BMI} = -10.94 +0.161Chest + 0.127Abdomen + 0.050Hip + 0.150 Thigh - 0.23Knee + 0.115Forearm $$
and both chest and abdomen are relatively more important in predicting BMI.

Looking at the $R^2$ value (multiple R-squared) from the summary output, 90.2% of the variability of density is explained by the regression on percentage of Height, Neck, Chest, Abdomen.
<ol>
<li>On average, holding the other variables constant, a 1 unit increase in Chest leads to a 0.161 unit increase in BMI </li>
<li>On average, holding the other variables constant, a 1 unit increase in Abdomen leads to a 0.127 unit increase in BMI </li>
<li>On average, holding the other variables constant, a 1 unit increase in Hip leads to a 0.050 unit increase in BMI </li>
<li>On average, holding the other variables constant, a 1 unit increase in Thigh leads to a 0.15 unit increase in BMI </li>
<li>On average, holding the other variables constant, a 1 unit increase in Knee leads to a 0.23 unit decrease in BMI </li>
<li>On average, holding the other variables constant, a 1 unit increase in Forearm leads to a 0.115 unit decrease in  BMI </li>
</ol>

***
### 2.3 Body Density
#### 2.3.1 Defining the model with population parameters
$$
Body Density = \beta_0 + \beta_1Pcf.BF + \beta_2Age + \beta_3Weight + \beta_4Height\\
+ \beta_5Neck + \beta_6Chest + \beta_7Abdomen + \beta_8Waist + \beta_9Hip + \beta_{10}Thigh\\ + \beta_{11}Knee + \beta_{12}Ankle + \beta_{13}Bicep + \beta_{14}Forearm + \beta_{15}Wrist + \epsilon
$$
```{r}
#data1<-data_density[,-2]
```


```{r}
cor_matrix <- cor(data_density)
pheatmap(cor_matrix, display_numbers = T,na.rm=T)
```

Above matrix has shown the interactice correlation between variables. Notbaly, Pct.BF has a -0.99 relationship with Density, which means Pct.BF could be used to explain Density. Meanwhile, variables having similar properties are linked together, which could be useful for generating groups.

#### 2.3.2 Check Assumptions
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.

```{r}
M0 <- lm(density ~ 1, data = data_density)  # Null model
M1 <- lm(density ~ ., data = data_density)  # Full model
autoplot(M1,which=1:2)+theme_bw()
round(summary(M1)$coef, 3)
```
```{r}
step.fwd.aic <- step(M0, scope = list(lower = M0, upper = M1), direction = "forward", trace = FALSE)
summary(step.fwd.aic)
step.back.aic <- step(M1, scope = list(lower = M0, upper = M1), direction = "backward", trace = FALSE)
summary(step.back.aic)
```
```{r}
exh <- regsubsets(density~., data = data_density, nvmax = 15)
plot(exh,scale="bic")
```


#### 2.3.3 Multiple Regression using the BIC
```{r}
M2<- lm(formula = density ~ neck + chest + abdomen, 
    data = data_density)
summary(M2)
```
```{r}
M3<- lm(formula = density ~ neck + chest + abdomen + waist , 
    data = data_density)
summary(M3)
```

Drop waist and add other variables
```{r}
M4<- lm(formula = density ~ neck + chest + abdomen + hip , 
    data = data_density)
summary(M4)
```

```{r}
M5<- lm(formula = density ~ neck + chest + abdomen + hip + thigh , 
    data = data_density)
summary(M5)
```

Drop chest and add other variables
```{r}
M6<- lm(formula = density ~ neck + abdomen + hip + thigh + knee , 
    data = data_density)
summary(M6)
```

Drop knee
```{r}
M7<- lm(formula = density ~ neck + abdomen + hip + thigh , 
    data = data_density)
summary(M7)
```


#### 2.3.4 Final Fitted Model
```{r}
relweights <- function(fit,...){
  R <- cor(fit$model)
  nvar <- ncol(R)
  rxx <- R[2:nvar, 2:nvar]
  rxy <- R[2:nvar, 1]
  svd <- eigen(rxx)
  evec <- svd$vectors
  ev <- svd$values
  delta <- diag(sqrt(ev))
  lambda <- evec %*% delta %*% t(evec)
  lambdasq <- lambda ^ 2
  beta <- solve(lambda) %*% rxy
  rsquare <- colSums(beta ^ 2)
  rawwgt <- lambdasq %*% beta ^ 2
  import <- (rawwgt / rsquare) * 100
  import <- as.data.frame(import)
  row.names(import) <- names(fit$model[2:nvar])
  names(import) <- "Weights"
  import <- import[order(import),1, drop=FALSE]
  dotchart(import$Weights, labels=row.names(import),
           xlab="% of R-Square", pch=19,
           main="Relative Importance of Predictor Variables",
           sub=paste("Total R-Square=", round(rsquare, digits=3)),
           ...)
  return(import)
}
relweights(bmi_step_back, col="blue")
```

Obviously, abdomen contributes the most in the relationship with body density.

The final model is:
$$
Body Density = 1.1104052 + 0.0019085 \times Neck\\
- 0.0022064 \times Abdomen\ + 0.0011314 \times Hip\\ - 0.0006094 \times Thigh\\
$$
Looking at the $R^2$ value (multiple R-squared) from the summary output, 70.4% of the variability of density is explained by the regression on percentage of Height, Neck, Chest, Abdomen.
<ol>
<li>On average, holding the other variables constant, a 1% increase in Neck leads to a 0.2% unit increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Abdomen leads to a 0.2% decrease in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Hip leads to a 0.1% increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Thigh leads to a 0.06% decrease in Density</li>
</ol>

#### 2.3.5 Linear regression assumptions for the stepwise model
```{r}
autoplot(M7,which=1:2)+theme_bw()
```

***
#### 2.4 Which variables can best predict whether a person is overweight?

Since the variable 'Overweight' is dichotomous (binary), we perform a logistical regression to interpret the relationship between overweight and other significant variables.

##### 2.4.1 Checking for Significance in a Logistic Regression
```{r,warning=FALSE}
data_overweight = data[-c(4:5,17)]
data_overweight$overweight = as.numeric(data_overweight$overweight)
glm1 = glm(overweight ~ ., data = data_overweight)
# drop knee
glm2 = glm(overweight ~ density + pct_bf + age + neck + chest + abdomen + waist + hip + thigh + ankle + bicep + forearm + wrist, data = data_overweight)
# drop ankle
glm3 = glm(overweight ~ density + pct_bf + age + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop density
glm4 = glm(overweight ~ pct_bf + age + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop age
glm5 = glm(overweight ~ pct_bf + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop waist
glm6 = glm(overweight ~ pct_bf + neck + chest + abdomen + hip + thigh + bicep + forearm + wrist, data = data_overweight)
```

```{r}
glm1 = glm(overweight ~ ., family = binomial, data = data_overweight)
# drop hip
glm2 = glm(overweight ~ density + pct_bf + age + neck + chest + abdomen + waist + knee + thigh + ankle + bicep + forearm + wrist, family = binomial, data = data_overweight)

# drop neck
glm3 = glm(overweight ~ density + pct_bf + age + chest + abdomen + waist + knee + thigh + ankle + bicep + forearm + wrist, family = binomial, data = data_overweight)
# drop forearm
glm4 = glm(overweight ~ density + pct_bf + age + chest + abdomen + waist + knee + thigh + ankle + bicep + wrist, family = binomial, data = data_overweight)
# drop pct_bf
glm5 = glm(overweight ~ density + age + chest + abdomen + waist + knee + thigh + ankle + bicep + wrist, family = binomial, data = data_overweight)
# drop wrist
glm6 = glm(overweight ~ density + age + chest + abdomen + waist + knee + thigh + ankle + bicep, family = binomial, data = data_overweight)
# drop age
glm7 = glm(overweight ~ density + chest + abdomen + waist + knee + thigh + ankle + bicep, family = binomial, data = data_overweight)
# drop knee
glm8 = glm(overweight ~ density + chest + abdomen + waist + thigh + ankle + bicep, family = binomial, data = data_overweight)
# drop ankle
glm9 = glm(overweight ~ density + chest + abdomen + waist + thigh + bicep, family = binomial, data = data_overweight)
# drop waist
glm10 = glm(overweight ~ density + chest + abdomen + thigh + bicep, family = binomial, data = data_overweight)
# drop density
glm11 = glm(overweight ~ chest + abdomen + thigh + bicep, family = binomial, data = data_overweight)
# drop bicep
glm12 = glm(overweight ~ chest + abdomen + thigh, family = binomial, data = data_overweight)
summary(glm12)
```
Before we start making predictions with the model, we drop the variables which are not a significant predictor for being overweight. The fitted model is shown below.

##### 2.4.2 Fitted Model (log odds scale)
$$
logit(p) = log(\frac{p}{1-p})  = -75.89380 + 0.37854Chest\\
+ 0.27128Abdomen + 0.22381Thigh\\
$$
where the logit(p) is a special link from our linear combination of predictors to the probability of the outcome being equal to 1, and the coefficients are interpreted as changes in log-odds.


##### 2.4.3 Visualising Coefficients (odds scale) and Predictions
```{r message=FALSE, warning=FALSE}
summary(glm12)
#tab_model(glm0, transform = NULL)
plot_model(glm12) + theme_bw(base_size = 10) + ylim(1, 2) + labs(x = "Overweight", y = "Odds Ratios", title = "Model Coefficients using odds scale",caption='Source: SOCR Data')
plot_model(glm12, type = "pred", terms = c("abdomen", "chest", "thigh"), show.data = TRUE) + theme_bw(base_size = 10) + labs(caption='Source: SOCR Data')
```

In the Coefficient graph, the three significant variables have similar odd ratios giving the model a smaller confidence interval.

From the Prediction graph, the positive slopes indicate a larger abdomen circumference leads to a high probability of being overweight.
Comparing the three individual graphs, the steeper slope indicates bicep circumference correlates with odds of being overweight.

##### 2.4.4 Evaluating (in-sample) performance
We correctly classified 91.2% of the observations, hence our resubstitution error rate, proportion of data predicted incorrectly using the fitted model, is 8.8%.
```{r}
glm0 = glm(overweight ~ chest + abdomen + bicep, family = binomial, data = data)
data = data %>% 
  mutate(pred_prob = predict(glm0, type = "response"),
         pred_surv = round(pred_prob))
mean(data$overweight == data$pred_surv)
table(data$pred_surv)
```

```{r}
confusion.glm = confusionMatrix(
  data = as.factor(data$pred_surv),
  reference = as.factor(data$overweight))
confusion.glm$table
confusion.glm
```
Based on the matrix above, out of the 117 + 8 not overweight people, the model successfully predicts 117 of them. Out of the 113 + 12 overweight people, the model successfully predicts 113 of them.

**The odds of being overweight for someone with an above average abdomen circumference of 110 is 5.31.**
```{r}
predict_overweight = data.frame(abdomen = 110, chest = mean(data$chest), thigh = mean(data$thigh))
predict(glm12, newdata = predict_overweight, type = "link")
```
**The odds of being overweight for someone with a below average abdomen circumference of 65 is -6.90.**
```{r}
predict_overweight = data.frame(abdomen = 65, chest = mean(data$chest), thigh = mean(data$thigh))
predict(glm12, newdata = predict_overweight, type = "link")
```
**The odds of being overweight for someone with slightly above average circumferences for their abdomen, chest, and bicep is 8.146941.**
```{r}
data_overweight$overweight=as.character(data_overweight$overweight)
data$pred_surv= as.factor(data$pred_surv)
data$overweight = as.factor(data$overweight)
library(caret)
confusion.glm = confusionMatrix(data = data$pred_surv, reference = data$overweight)
confusion.glm$table
```

```{r message=FALSE}
library(partykit)
library(rpart)
data_overweight$overweight=as.character(data_overweight$overweight)
```

```{r}
ov_tree = rpart(overweight ~ abdomen + chest + bicep, data = data_overweight, method = "class",control = rpart.control(cp = 0.009))
predict_overweight = data.frame(abdomen = mean(data$abdomen)*1.1, chest = mean(data$chest)*1.1, thigh = mean(data$thigh)*1.1)
predict(glm12, newdata = predict_overweight, type = "link")
```


##### 2.4.5 Decision Tree
```{r}
data$overweight=as.character(data$overweight)
ov_tree = rpart(overweight ~ abdomen + chest + thigh, data = data, method = "class",control = rpart.control(cp = 0.008))
ov_tree
plot(as.party(ov_tree))
```

Out of a total of 250 observations, **96%** of people with a chest circumference greater or equal to 101.55cm are overweight. Also, of the people with a chest circumference less than 101.55cm, those with an abdomen circumference greater or equal to 92.6cm are **72%** likely to be overweight. On the other hand, those with an abdomen circumference less than 92.6cm are **92%** likely to be NOT overweight.


#### 2.5.1 Interpretation


## 3. Limitations
<ol>
<li>Gender Bias</li>
<li>Privacy Issues</li>
<li>Age Range</li>
<li></li>
</ol>
## 4. Conclusion

## 5. References
<ol>
<li>  Australian Institute of Health and Welfare (AIHW). (2019). Overweight & obesity. Australian Government. Retrieved from <https://www.aihw.gov.au/reports-data/behaviours-risk-factors/overweight-obesity/overview> </li>

</li> DASL. (n.d.). Bodyfat. DASL. Retrieved from < https://dasl.datadescription.com/datafile/bodyfat> </li>

</li> Rahman, A., & Harding, A. (2013). Prevalence of overweight and obesity epidemic in Australia: some causes and consequences. JP Journal of Biostatistics, 10(1), 31-48. </li>

</li> Stein, C. J., & Colditz, G. A. (2004). The epidemic of obesity. The Journal of Clinical Endocrinology & Metabolism, 89(6), 2522-2525. </li>
</ol> 

