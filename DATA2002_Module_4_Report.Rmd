---
title: "DATA2002 Module 4 Report"
author: "Group 9 (460352996,480407614,480145820,470066919)"
output: 
  html_document:
    theme: simplex
    code_folding: hide
    toc: true
    toc_float: true
---

```{r load_packages, include=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
library(knitr)
library(janitor)
library("readxl")
library(ggfortify)
library(GGally)
library(qtlcharts)
library(leaps)
library(sjPlot)
library(pheatmap)
```

***

## 1. Introduction

The data set is adapted from th  

### 1.1 Sampling method and potential biases



### 1.2 Data import, processing and cleaning
```{r import_data, message=FALSE, warning=FALSE}
data = read.delim("bodyfat.txt") %>% janitor::clean_names()
data = data %>%
  mutate(bmi = (data$weight/(data$height ^ 2)) * 703,
         overweight = case_when(
          bmi >= 25 ~ 1,
          bmi < 25 ~ 0))

#colnames(data)
data_bmi = data[-c(1:2,4:5,18)]
data_bf = data[-c(1,3:5,17:18)]
data_density = data[-c(2:5,17:18)]
#glimpse(data)
```

***
## 2. Analysis
### Prediction for Obesity
Due to the increasing consumptions of fast food and the increasing convenience of food deliveries, concerns about obesity level is rising throughput the world and has reached a new high. This increasing concern has lead to an increasing need to measure obesity accurately and percentage body fat is arguably the most accurate measure by far. However, the calculation of body fat is difficult and many has switched to Body Mass Index (BMI) for simpler calculation. This section is looking at comparing the results from predicting body fat percentage using other body measurements and  predicting BMI using other body measurements to determine wh body measurement is the most important in determining obesity.

#### 2.1 Body Fat Percentage
##### 2.1.1 Data Visualisation
```{r}
qtlcharts::iplotCorr(data_bf)
```
Based on the interactive correlation matrix, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is adopted.

##### 2.1.2 Multiple Regression
```{r}
bf_lm = lm(pct_bf~.,data=data_bf)
summary(bf_lm)
```
Using the individual p-value method, the varaibles that need to be dropped are chest, waist, thigh, knee,ankle, bicep, forearm with ankle being the first to drop down due to its high p-value. However, to double check, the AIC criterion will also be considered.

```{r}
bf_step_back = step(bf_lm, direction = "backward",trace = FALSE)
summary(bf_step_back)
```
Based on the backward selection model, the fitted model has become:

$\hat{body_fat} = 1.52 -0.3965neck - 0.128chest + 1.01805abdomen -0.28758hip + 0.26bicep -1.55084wrist $

##### 2.1.3 Check Assumptions
Finally, to check assumption, we perform the ggfortify function.
```{r}
par(mfrow=c(1,2))
plot(bf_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a slight variation; but given that body fat is hard to predict, this is acceptable.

##### 2.1.4 Final fitted model
$\hat{body_fat} = 1.52 -0.3965neck - 0.128chest + 1.01805abdomen -0.28758hip + 0.26bicep -1.55084wrist $

#### 2.2 BMI
For this analysis, the formula of BMI is $BMI = \frac{Weight (lbs)*703}{Height(in)^2}$

##### 2.2.1 Data Visualisation
```{r}
qtlcharts::iplotCorr(data_bmi)
```
Based on the interactive correlation matrix, it can be seen the level of correlation differs quite drastically between the variables and the backward variable selection method is adopted.

##### 2.2.2 Multiple Regression

```{r}
bmi_lm = lm(bmi~.,data=data_bmi)
summary(bmi_lm)
```

Using the individual p-value method, the varaibles that need to be dropped are hip, ankle, bicep, forearm and wrist. To double check, the AIC criterion will also be considered.

```{r}
bmi_step_back = step(bmi_lm, direction = "backward",trace = FALSE)
summary(bmi_step_back)
```

Based on the backward selection model, the fitted model has become:

$\hat{bmi} = -10.94 +0.161chest + 0.127abdomen + 0.050hip + 0.150 thigh - 0.23knee + 0.115forearm $

##### 2.2.3 Check Assumptions
Finally, to check assumption, we perform the ggfortify function.

```{r}
par(mfrow=c(1,2))
plot(bmi_step_back,which=1:2) + theme_bw()
```

The QQ plot shows a straight line which indicates that the normality assumption is reasonable. However, the residuals vs fitted plot shows a fan shaped plot which indicates that the assumption of homogeneous variance is violated. We can use a log transformed response and re-fit the linear regression.

```{r}
ln_bmi_lm = lm(log(bmi)~.,data=data_bmi)
summary(ln_bmi_lm)
ln_bmi_step_back = step(ln_bmi_lm, direction = "backward",trace = FALSE)
summary(ln_bmi_step_back)
par(mfrow=c(1,2))
plot(ln_bmi_step_back,which=1:2) + theme_bw()
```

```{r}
sjPlot::tab_model(bmi_step_back, ln_bmi_step_back, digits = 5, show.ci = FALSE)
```

##### 2.2.4 Final Fitted Model

$log(\hat{bmi}) = 1.83 +0.0058chest + 0.0052abdomen + 0.0064 thigh -0.0065knee +        0.0028bicep + 0.0040 forearm $.


#### 2.3 Body Density
##### 2.3.1 Defining the model with population parameters
$$
Body Density = \beta_0 + \beta_1Pcf.BF + \beta_2Age + \beta_3Weight + \beta_4Height\\
+ \beta_5Neck + \beta_6Chest + \beta_7Abdomen + \beta_8Waist + \beta_9Hip + \beta_{10}Thigh\\ + \beta_{11}Knee + \beta_{12}Ankle + \beta_{13}Bicep + \beta_{14}Forearm + \beta_{15}Wrist + \epsilon
$$
```{r}
#data1<-data_density[,-2]
```


```{r}
cor_matrix <- cor(data_density)
pheatmap(cor_matrix, display_numbers = T,na.rm=T)
```

Above matrix has shown the interactice correlation between variables. Notbaly, Pct.BF has a -0.99 relationship with Density, which means Pct.BF could be used to explain Density. Meanwhile, variables having similar properties are linked together, which could be useful for generating groups.

##### 2.3.2 Check Assumptions
The residuals $\epsilon_i$ are iid $N(0,\sigma^2)$ and there is a linear relationship between y and x.

```{r}
M0 <- lm(density ~ 1, data = data_density)  # Null model
M1 <- lm(density ~ ., data = data_density)  # Full model
autoplot(M1,which=1:2)+theme_bw()
round(summary(M1)$coef, 3)
```
```{r}
step.fwd.aic <- step(M0, scope = list(lower = M0, upper = M1), direction = "forward", trace = FALSE)
summary(step.fwd.aic)
step.back.aic <- step(M1, scope = list(lower = M0, upper = M1), direction = "backward", trace = FALSE)
summary(step.back.aic)
```
```{r}
exh <- regsubsets(density~., data = data_density, nvmax = 15)
plot(exh,scale="bic")
```


##### 2.3.3 Adding variables using the BIC
```{r}
M2<- lm(formula = density ~ neck + chest + abdomen, 
    data = data_density)
summary(M2)
```
```{r}
M3<- lm(formula = density ~ neck + chest + abdomen + waist , 
    data = data_density)
summary(M3)
```

Drop waist and add other variables
```{r}
M4<- lm(formula = density ~ neck + chest + abdomen + hip , 
    data = data_density)
summary(M4)
```

```{r}
M5<- lm(formula = density ~ neck + chest + abdomen + hip + thigh , 
    data = data_density)
summary(M5)
```

Drop chest and add other variables
```{r}
M6<- lm(formula = density ~ neck + abdomen + hip + thigh + knee , 
    data = data_density)
summary(M6)
```

Drop knee
```{r}
M7<- lm(formula = density ~ neck + abdomen + hip + thigh , 
    data = data_density)
summary(M7)
```

```{r}


```

Obviously, abdomen contributes the most in the relationship with body density.

##### 2.3.4 Fitted model for the model selected by the step-wise procedure.
$$
Body Density = 1.1104052 + 0.0019085 \times Neck\\
- 0.0022064 \times Abdomen\ + 0.0011314 \times Hip\\ - 0.0006094 \times Thigh\\
$$
Looking at the $R^2$ value (multiple R-squared) from the summary output, 70.4% of the variability of density is explained by the regression on percentage of Height, Neck, Chest, Abdomen.
<ol>
<li>On average, holding the other variables constant, a 1% increase in Neck leads to a 0.2% unit increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Abdomen leads to a 0.2% decrease in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Hip leads to a 0.1% increase in Density</li>
<li>On average, holding the other variables constant, a 1% increase in Thigh leads to a 0.06% decrease in Density</li>
</ol>

##### 2.3.5 Linear regression assumptions for the stepwise model
```{r}
autoplot(M7,which=1:2)+theme_bw()
```

***
#### 2.4 Which variables can best predict whether a person is overweight?

Since overweight is a binary field.. logistical regression....

##### 2.4.1 Checking for Significance in a Logistic Regression
```{r}
data_overweight = data[-c(4:5,17)]
glm1 = glm(overweight ~ ., data = data_overweight)
# drop knee
glm2 = glm(overweight ~ density + pct_bf + age + neck + chest + abdomen + waist + hip + thigh + ankle + bicep + forearm + wrist, data = data_overweight)
# drop ankle
glm3 = glm(overweight ~ density + pct_bf + age + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop density
glm4 = glm(overweight ~ pct_bf + age + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop age
glm5 = glm(overweight ~ pct_bf + neck + chest + abdomen + waist + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop waist
glm6 = glm(overweight ~ pct_bf + neck + chest + abdomen + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop neck
glm7 = glm(overweight ~ pct_bf + chest + abdomen + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop pct_bf
glm8 = glm(overweight ~ chest + abdomen + hip + thigh + bicep + forearm + wrist, data = data_overweight)
# drop waist
glm9 = glm(overweight ~ chest + abdomen + hip + thigh + bicep + forearm, data = data_overweight)
# drop wrist
glm10 = glm(overweight ~ chest + abdomen + hip + thigh + bicep + forearm, data = data_overweight)
# drop forearm
glm11 = glm(overweight ~ chest + abdomen + hip + thigh + bicep, data = data_overweight)
# drop thigh
glm12 = glm(overweight ~ chest + abdomen + hip + bicep, data = data_overweight)
# drop hip
glm13 = glm(overweight ~ chest + abdomen + bicep, data = data_overweight)
summary(glm13)
```
Before we start making predictions with the model, we drop the variables which are not a significant predictor for being overweight. The fitted model is shown below.

##### 2.4.2 Fitted Model
$$
logit(p) = log(\frac{p}{1-p})  = -3.845275 + 0.013281 \times Chest\\
+ 0.020164 \times Abdomen\ + 0.035618 \times bicep\\
$$
where the logit(p) is a special link from our linear combination of predictors to the probability of the outcome being equal to 1, and the coefficients are interpreted as changes in log-odds.


##### 2.4.3 Visualisation and Output of the model coefficients (odds scale)
```{r message=FALSE}
tab_model(glm13)
plot_model(glm13) + theme_bw(base_size = 10) + ylim(0, 0.10) + labs(x = "Overweight", y = "Odds Ratios", title = "Model Coefficients using odds scale")
plot_model(glm13, type = "pred", terms = c("abdomen", "chest", "bicep"), show.data = TRUE) +
  theme_bw(base_size = 10)
```

In the Coefficient graph, the three significant variables have similar odd ratios giving the model a smaller confidence interval.

From the Prediction graph, the positive slopes in the highlighted areas indicate a larger abdomen and chest circumference leads to a high probability of being overweight.
Comparing the three individual graphs, the slight difference in the slope's y axis indicates bicep circumference correlates with odds of being overweight.


##### 2.4.4 Predictions
We correctly classified 91.2% of the observations, hence our resubstitution error rate, proportion of data predicted incorrectly using the fitted model, is 8.8%.
```{r}
glm0 = glm(overweight ~ chest + abdomen + bicep, data = data)
data = data %>% 
  mutate(pred_prob = predict(glm0, type = "response"),
         pred_surv = round(pred_prob))
mean(data$overweight == data$pred_surv)

# not working
#library(caret)
#confusion.glm = confusionMatrix(
#  data = as.factor(data$pred_surv), 
#  reference = as.factor(data$overweight))
#confusion.glm$table
```

**The odds of being overweight for someone with an above average abdomen circumference of 120 is 1.26.**
```{r}
predict_overweight = data.frame(abdomen = 130, chest = mean(data$chest), bicep = mean(data$bicep))
predict(glm13, newdata = predict_overweight, type = "link")
```
**The odds of being overweight for someone with a below average abdomen circumference of 60 is -0.15.**
```{r}
predict_overweight = data.frame(abdomen = 60, chest = mean(data$chest), bicep = mean(data$bicep))
predict(glm13, newdata = predict_overweight, type = "link")
```
**The odds of being overweight for someone with above average circumferences for their abdomen, chest, and bicep is 1.37.**
```{r}
predict_overweight = data.frame(abdomen = mean(data$abdomen)*1.2, chest = mean(data$chest)*1.2, bicep = mean(data$bicep)*1.2)
predict(glm13, newdata = predict_overweight, type = "link")
```




##### DECISION TREE NOT WORKING delete??

```{r message=FALSE}
library(partykit)
library(rpart)
ov_tree = rpart(overweight ~ abdomen + chest + bicep, data = data_overweight, method = "class",control = rpart.control(cp = 0.009))
ov_tree
plot(as.party(ov_tree))
```


## 3. Limitations
<ol>
<li>Gender Bias</li>
<li>Privacy Issues</li>
<li>Age Range</li>
<li></li>
</ol>
## 4. Conclusion

## 5. References
<ol>
<li>  </li>
</ol> 

